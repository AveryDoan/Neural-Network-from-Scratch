{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Build Your Own Neural Network from Scratch\n",
                "\n",
                "Welcome! This notebook demonstrates how to build and train a neural network using a **modular architecture**. \n",
                "\n",
                "### Why Modular?\n",
                "In real-world frameworks like PyTorch or TensorFlow, neural networks are built by stacking independent components (Layers). This modularity allows us to:\n",
                "1. **Understand** each part in isolation (Linear, Activation, Loss).\n",
                "2. **Customize** the architecture easily (add more layers, change sizes).\n",
                "3. **Debug** specific components during the backward pass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "import os\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.datasets import make_blobs\n",
                "\n",
                "# Fix for ModuleNotFoundError in some environments\n",
                "sys.path.append(os.path.abspath(\".\"))\n",
                "from neural_network import Linear, ReLU, Sequential, CrossEntropyLoss, SGD\n",
                "\n",
                "np.random.seed(42)\n",
                "\n",
                "def load_data(n_samples=2000, n_features=4, centers=3):\n",
                "    \"\"\"Generates synthetic data (blobs) for classification.\"\"\"\n",
                "    X, y = make_blobs(n_samples=n_samples, centers=centers, n_features=n_features, random_state=42)\n",
                "    y_oh = np.eye(centers)[y] # One-hot encode targets\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y_oh, test_size=0.2, random_state=42)\n",
                "    return X_train, X_test, y_train, y_test, centers\n",
                "\n",
                "X_train, X_test, y_train, y_test, num_classes = load_data()\n",
                "print(f\"Data loaded: {X_train.shape[0]} training samples, {X_test.shape[0]} test samples.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Design Your Network\n",
                "\n",
                "Here you can customize the **important parameters**:\n",
                "- `hidden_dim`: Number of neurons in the hidden layer (try 8, 32, or 128).\n",
                "- `learning_rate`: How fast the model learns (try 0.1, 0.01, or 0.001).\n",
                "- `regularization`: Prevents overfitting (try 1e-4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- CUSTOMIZE THESE PARAMETERS ---\n",
                "HIDDEN_DIM = 64\n",
                "LEARNING_RATE = 0.1\n",
                "REGULARIZATION = 1e-4\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 32\n",
                "# ----------------------------------\n",
                "\n",
                "input_dim = X_train.shape[1]\n",
                "output_dim = num_classes\n",
                "\n",
                "# Build the model\n",
                "model = Sequential([\n",
                "    Linear(input_dim, HIDDEN_DIM),\n",
                "    ReLU(),\n",
                "    Linear(HIDDEN_DIM, output_dim)\n",
                "])\n",
                "\n",
                "loss_fn = CrossEntropyLoss()\n",
                "optimizer = SGD(model.layers, lr=LEARNING_RATE, reg=REGULARIZATION)\n",
                "\n",
                "print(f\"Model built with {HIDDEN_DIM} hidden units.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. The Training Loop\n",
                "\n",
                "This is where the \"learning\" happens in 3 steps:\n",
                "1. **Forward**: Data passes through layers to get predictions.\n",
                "2. **Loss**: Measure how far off we are from the truth.\n",
                "3. **Backward**: Calculate gradients and use SGD to update weights."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_accuracy(model, X, y):\n",
                "    scores = model.forward(X)\n",
                "    preds = np.argmax(scores, axis=1)\n",
                "    targets = np.argmax(y, axis=1)\n",
                "    return np.mean(preds == targets)\n",
                "\n",
                "losses = []\n",
                "N = X_train.shape[0]\n",
                "\n",
                "for epoch in range(1, EPOCHS + 1):\n",
                "    # Shuffle data for each epoch\n",
                "    indices = np.random.permutation(N)\n",
                "    X_shuffled = X_train[indices]\n",
                "    y_shuffled = y_train[indices]\n",
                "    \n",
                "    epoch_loss = 0\n",
                "    for i in range(0, N, BATCH_SIZE):\n",
                "        xb = X_shuffled[i:i+BATCH_SIZE]\n",
                "        yb = y_shuffled[i:i+BATCH_SIZE]\n",
                "        \n",
                "        # 1. Forward pass\n",
                "        scores = model.forward(xb)\n",
                "        \n",
                "        # 2. Compute Loss\n",
                "        loss = loss_fn.loss(scores, yb)\n",
                "        epoch_loss += loss\n",
                "        \n",
                "        # 3. Backward pass (Gradients)\n",
                "        dloss = loss_fn.backward(yb)\n",
                "        model.backward(dloss)\n",
                "        \n",
                "        # 4. Optimization step\n",
                "        optimizer.step()\n",
                "        \n",
                "    avg_loss = epoch_loss / (N / BATCH_SIZE)\n",
                "    losses.append(avg_loss)\n",
                "    \n",
                "    if epoch % 10 == 0:\n",
                "        train_acc = calculate_accuracy(model, X_train, y_train)\n",
                "        test_acc = calculate_accuracy(model, X_test, y_test)\n",
                "        print(f\"Epoch {epoch}/{EPOCHS} | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.3f} | Test Acc: {test_acc:.3f}\")\n",
                "\n",
                "plt.plot(losses)\n",
                "plt.title(\"Training Loss Over Time\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Visualize Predictions\n",
                "\n",
                "Let's see how our model performs visually by plotting the decision boundaries (if possible) or just checking a few random samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sample_idx = np.random.randint(0, X_test.shape[0], 5)\n",
                "for idx in sample_idx:\n",
                "    x = X_test[idx:idx+1]\n",
                "    y = y_test[idx]\n",
                "    scores = model.forward(x)\n",
                "    pred = np.argmax(scores)\n",
                "    actual = np.argmax(y)\n",
                "    print(f\"Sample {idx}: Prediction={pred}, Actual={actual} {'✅' if pred == actual else '❌'}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}